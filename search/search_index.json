{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"data_download/","title":"Data download","text":"<p>To download data use data_downloading pipeline by running</p> <pre><code>kedro run\u00a0--pipeline=data_downloading\n</code></pre> <p>Alternatively you can download data manually by following instructions at goemotions to get datasets <code>goemotions_1.csv</code>, <code>goemotions_2.csv</code> and <code>goemotions_3.csv</code>. To get final dataset concatenate them into one <code>data/01_raw/goemotions-full-raw.csv</code> file.</p>"},{"location":"data_download/#overview","title":"Overview","text":"<p>This pipeline downloads raw data from google storage, concatenates it into one csv and saves it at <code>data/01_raw/goemotions-full-raw.csv</code>.</p>"},{"location":"data_download/#pipeline-inputs","title":"Pipeline inputs","text":"<p>List of remote datasets defined in <code>conf/base/catalog.yml</code>. In our case : <code>[\"remote-full-dataset-1\", \"remote-full-dataset-2\", \"remote-full-dataset-3\"]</code></p>"},{"location":"data_download/#nodes","title":"Nodes:","text":""},{"location":"data_download/#src.deepemotions.pipelines.data_download.nodes.download_data","title":"<code>download_data(*remote_datasets)</code>","text":"<p>Concatenates all remote datasets into one csv.</p> <p>Parameters:</p> Name Type Description Default <code>remote_datasets</code> <code>list(pandas.CSVDataSet)) </code> <p>csv datasets defined in conf/base/catalog.yml</p> <code>()</code> <p>Returns:</p> Name Type Description <code>full_dataset</code> <code>pandasCSVDataSet</code> <p>concatenated dataset</p> Source code in <code>src/deepemotions/pipelines/data_download/nodes.py</code> <pre><code>def download_data(*remote_datasets) -&gt; None:\n\"\"\"\n    Concatenates all remote datasets into one csv.\n\n    Args:\n        remote_datasets (list(pandas.CSVDataSet)) : csv datasets defined in conf/base/catalog.yml\n    Returns: \n        full_dataset(pandasCSVDataSet):  concatenated dataset\n    \"\"\"\n    # Concatenate all the datasets\n    full_dataset = pd.concat(remote_datasets)\n    print(\"Downloaded full datset of lenght:\", len(full_dataset))\n\n    return full_dataset\n</code></pre>"},{"location":"data_preprocess/","title":"Data preprocess","text":"<p>Do preprocess data use data_preprocess pipeline by running</p> <pre><code>kedro run\u00a0--pipeline=data_preprocess\n</code></pre>"},{"location":"data_preprocess/#overview","title":"Overview","text":"<p>This pipeline preproceses downloaded dataset <code>data/01_raw/goemotions-full-raw.csv</code> and saves it in <code>data/02_intermediate/formated_full.csv</code></p>"},{"location":"data_preprocess/#pipeline-inputs","title":"Pipeline inputs","text":"<p><code>full-raw-dataset</code> : pandas.CSVDataSet stored in <code>data/01_raw/goemotions-full-raw.csv</code></p>"},{"location":"data_preprocess/#nodes","title":"Nodes:","text":""},{"location":"data_preprocess/#src.deepemotions.pipelines.data_preprocess.nodes.drop_discordant_annotations","title":"<code>drop_discordant_annotations(grouped_dataset)</code>","text":"<p>Drops annotations given by just one rater.</p> <p>Parameters:</p> Name Type Description Default <code>grouped_dataset</code> <code>pandas.CSVDataSet</code> <p>dataset grouped by comment id</p> required <p>Returns:</p> Type Description <code>pandas.CSVDataSet</code> <p>pre filtered dataset</p> Source code in <code>src/deepemotions/pipelines/data_preprocess/nodes.py</code> <pre><code>def drop_discordant_annotations(grouped_dataset):\n\"\"\"Drops annotations given by just one rater.\n\n    Args:\n        grouped_dataset (pandas.CSVDataSet): dataset grouped by comment id\n\n    Returns:\n        (pandas.CSVDataSet): pre filtered dataset\n    \"\"\"\n    pre_filtered_dataset = grouped_dataset.sum().replace(0, None).melt(\n        id_vars=\"text\", var_name=\"emotion\", value_name=\"num_rated\",\n        ignore_index=False).dropna()\n    pre_filtered_dataset = pre_filtered_dataset[\n        pre_filtered_dataset[\"num_rated\"] &gt; 1]\n    return pre_filtered_dataset \n</code></pre>"},{"location":"data_preprocess/#src.deepemotions.pipelines.data_preprocess.nodes.drop_unclear_annotations","title":"<code>drop_unclear_annotations(pre_filtered_dataset)</code>","text":"<p>Removes unclear examples from dataset.</p> <p>Parameters:</p> Name Type Description Default <code>pre_filtered_dataset</code> <code>pandas.CSVDataSet</code> <p>pre filtered dataset</p> required <p>Returns:</p> Type Description <code>pandas.CSVDataSet</code> <p>filtered dataset</p> Source code in <code>src/deepemotions/pipelines/data_preprocess/nodes.py</code> <pre><code>def drop_unclear_annotations(pre_filtered_dataset):\n\"\"\"Removes unclear examples from dataset.\n\n    Args:\n        pre_filtered_dataset (pandas.CSVDataSet): pre filtered dataset\n\n    Returns:\n        (pandas.CSVDataSet): filtered dataset\n    \"\"\"\n    filtered_dataset = pre_filtered_dataset[\n        ~pre_filtered_dataset[\"emotion\"].isin([\"example_very_unclear\"])]\n    return filtered_dataset\n</code></pre>"},{"location":"data_preprocess/#src.deepemotions.pipelines.data_preprocess.nodes.format_dataset","title":"<code>format_dataset(mapped_filterd_dataset)</code>","text":"<p>Format dataset.</p> Formated dataset has following columns <ul> <li>text : text of the comment</li> <li>emotion : numerical values of emotions annotated to comment</li> <li>id : unique record identifier</li> </ul> <p>Parameters:</p> Name Type Description Default <code>mapped_filterd_dataset</code> <code>pandas.CSVDataSet</code> <p>mapped and filtered dataset to format</p> required <p>Returns:</p> Type Description <code>pandas.CSVDataSet</code> <p>formated dataset</p> Source code in <code>src/deepemotions/pipelines/data_preprocess/nodes.py</code> <pre><code>def format_dataset(mapped_filterd_dataset):\n\"\"\"Format dataset.\n    Formated dataset has following columns:\n        - text : text of the comment\n        - emotion : numerical values of emotions annotated to comment\n        - id : unique record identifier\n\n    Args:\n        mapped_filterd_dataset (pandas.CSVDataSet): mapped and filtered dataset to format\n\n    Returns:\n        (pandas.CSVDataSet): formated dataset\n    \"\"\"\n    formated_dataset = mapped_filterd_dataset.drop(\"num_rated\", axis = \"columns\")\n    formated_dataset = formated_dataset.reset_index()\n    formated_dataset[\"emotion\"] = formated_dataset[\"emotion\"].astype(str)\n    formated_dataset = formated_dataset.groupby([\"id\", \"text\"]).agg({'emotion': ';'.join})\n    formated_dataset = formated_dataset.reset_index()\n    formated_dataset = formated_dataset[[\"text\", \"emotion\", \"id\"]]\n    return formated_dataset\n</code></pre>"},{"location":"data_preprocess/#src.deepemotions.pipelines.data_preprocess.nodes.group_dataset","title":"<code>group_dataset(narrowed_dateset)</code>","text":"<p>Groups data in dataset by comment id.</p> <p>Parameters:</p> Name Type Description Default <code>narrowed_dateset</code> <code>pandas.CSVDataSet</code> <p>dataset with only relevant columns</p> required <p>Returns:</p> Type Description <code>CSVDataSet</code> <p>grouped dataset</p> Source code in <code>src/deepemotions/pipelines/data_preprocess/nodes.py</code> <pre><code>def group_dataset(narrowed_dateset):\n\"\"\"Groups data in dataset by comment id.\n\n    Args:\n        narrowed_dateset (pandas.CSVDataSet): dataset with only relevant columns\n\n    Returns:\n        (CSVDataSet): grouped dataset\n    \"\"\"\n    grouped_dataset = narrowed_dateset.groupby([\"id\"])\n    return grouped_dataset \n</code></pre>"},{"location":"data_preprocess/#src.deepemotions.pipelines.data_preprocess.nodes.make_emotions_dicts","title":"<code>make_emotions_dicts(filtered_dataset)</code>","text":"<p>Create mapping between emotions(categories) names and their numerical ids.</p> <p>Parameters:</p> Name Type Description Default <code>filtered_dataset</code> <code>pandas.CSVDataSet</code> <p>filtered dataset</p> required <p>Returns:</p> Type Description <code>tuple(dict(int: string), dict(string: int))</code> <p>mapping from id to emotion name, and from emotion name to id</p> Source code in <code>src/deepemotions/pipelines/data_preprocess/nodes.py</code> <pre><code>def make_emotions_dicts(filtered_dataset):\n\"\"\"Create mapping between emotions(categories) names and their numerical ids.\n\n    Args:\n        filtered_dataset (pandas.CSVDataSet): filtered dataset\n\n    Returns:\n        (tuple(dict(int: string), dict(string: int))): mapping from id to emotion name, and from emotion name to id\n    \"\"\"\n    emotions = filtered_dataset[\"emotion\"].unique()\n    id_to_emotions_dict = {key: value for key, value in enumerate(emotions)}\n    emotions_to_id_dict = {key: value for value, key in enumerate(emotions)}\n    return id_to_emotions_dict, emotions_to_id_dict\n</code></pre>"},{"location":"data_preprocess/#src.deepemotions.pipelines.data_preprocess.nodes.map_emotions","title":"<code>map_emotions(filtered_dataset, emotion_mapping)</code>","text":"<p>Replaces string names of emotions with their ids</p> <p>Parameters:</p> Name Type Description Default <code>filtered_dataset</code> <code>pandas.CSVDataSet</code> <p>filtered dataset to process</p> required <code>emotion_mapping</code> <code>dict</code> <p>mapping between emotion names and their ids.</p> required <p>Returns:</p> Type Description <code>CSVDataSet</code> <p>mapped filtered dataset</p> Source code in <code>src/deepemotions/pipelines/data_preprocess/nodes.py</code> <pre><code>def map_emotions(filtered_dataset, emotion_mapping):\n\"\"\"Replaces string names of emotions with their ids\n\n    Args:\n        filtered_dataset (pandas.CSVDataSet): filtered dataset to process\n        emotion_mapping (dict): mapping between emotion names and their ids.\n\n    Returns:\n        (CSVDataSet): mapped filtered dataset\n    \"\"\"\n    mapped_filtered_dataset = filtered_dataset.replace({\"emotion\" : emotion_mapping})\n    return mapped_filtered_dataset\n</code></pre>"},{"location":"data_preprocess/#src.deepemotions.pipelines.data_preprocess.nodes.narrow_dataset","title":"<code>narrow_dataset(dataset)</code>","text":"<p>Drops unnecesary columns from dataset.  Remaining columns are: 'text', 'id', 'example_very_unclear' and columns representing emotion categories.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>pandas.CSVDataSet</code> <p>Dataset to be processed</p> required <p>Returns:</p> Type Description <code>pandas.CSVDataSet</code> <p>narrowed dataset</p> Source code in <code>src/deepemotions/pipelines/data_preprocess/nodes.py</code> <pre><code>def narrow_dataset(dataset):\n\"\"\"Drops unnecesary columns from dataset. \n    Remaining columns are: 'text', 'id', 'example_very_unclear' and columns representing emotion categories.\n\n    Args:\n        dataset (pandas.CSVDataSet): Dataset to be processed\n\n    Returns:\n        (pandas.CSVDataSet): narrowed dataset\n    \"\"\"\n    unnecesary_columns=[\"author\", \"subreddit\", \"link_id\",\n                        \"parent_id\", \"created_utc\", \"rater_id\"]\n    narrowed_dataset = dataset.drop(unnecesary_columns,\n                                    axis = \"columns\")\n    return narrowed_dataset\n</code></pre>"},{"location":"instalation/","title":"Installation","text":"<p>Follow this instruction install project and setup environment.</p>"},{"location":"instalation/#1-clone-the-repository","title":"1) Clone the repository","text":"<pre><code>git clone https://github.com/nerkulec/deepemotions.git\n</code></pre> <p>or </p> <pre><code>git clone git@github.com:nerkulec/deepemotions.git\n</code></pre>"},{"location":"instalation/#2-setup-environment","title":"2) Setup environment","text":"<p>To install this project make sure you have conda installed. After that simply open terminal, go to project folder and type:  </p> <pre><code>conda env create --file conda.yml\nconda activate deepemotions\npip install -r requirements.txt\n</code></pre>"},{"location":"model_download/","title":"Model download","text":"<p>To download model use model_downloading pipeline by running</p> <pre><code>kedro run\u00a0--pipeline=model_download\n</code></pre>"},{"location":"model_download/#overview","title":"Overview","text":"<p>This pipeline downloads pre train bert model.</p>"},{"location":"model_download/#pipeline-inputs","title":"Pipeline inputs","text":"<p>model_name(string) defined in <code>conf.base.parameters.model_download.yml</code></p>"},{"location":"model_download/#nodes","title":"Nodes:","text":""},{"location":"model_download/#src.deepemotions.pipelines.model_download.nodes.load_model","title":"<code>load_model(model_name, num_labels)</code>","text":"<p>Load Bert model</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>string</code> <p>Name of bert model to load</p> required <code>num_labels</code> <code>int</code> <p>Number of classess</p> required <p>Returns:</p> Type Description <code>BertModel</code> <p>loaded pretrained model</p> Source code in <code>src/deepemotions/pipelines/model_download/nodes.py</code> <pre><code>def load_model(model_name, num_labels):\n\"\"\"Load Bert model\n\n  Args:\n      model_name (string): Name of bert model to load\n      num_labels (int): Number of classess\n\n  Returns:\n      (BertModel): loaded pretrained model\n  \"\"\"\n  model = BertModel.from_pretrained(model_name, num_labels=num_labels)\n\n  return model\n</code></pre>"},{"location":"model_download/#src.deepemotions.pipelines.model_download.nodes.load_tokenizer","title":"<code>load_tokenizer(model_name)</code>","text":"<p>Loads Bert Tokenizer</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>string</code> <p>Name of bert tokenizer to be used</p> required <p>Returns:</p> Type Description <code>BertTokenizer</code> <p>tokenizer</p> Source code in <code>src/deepemotions/pipelines/model_download/nodes.py</code> <pre><code>def load_tokenizer(model_name):\n\"\"\"Loads Bert Tokenizer\n\n  Args:\n      model_name (string): Name of bert tokenizer to be used\n\n  Returns:\n      (BertTokenizer): tokenizer\n  \"\"\"\n  tokenizer = BertTokenizer.from_pretrained(model_name)\n\n  return tokenizer\n</code></pre>"}]}